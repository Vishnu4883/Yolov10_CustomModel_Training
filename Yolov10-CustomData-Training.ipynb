{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9RrPXGuLliPG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749188041817,"user_tz":-330,"elapsed":137,"user":{"displayName":"NTR","userId":"00862839579670445590"}},"outputId":"f8042de9-0ed4-425d-d4f5-6bf29b445e80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Jun  6 05:34:00 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCHXSi74mPEZ","executionInfo":{"status":"ok","timestamp":1749118748139,"user_tz":-330,"elapsed":23676,"user":{"displayName":"NTR","userId":"00862839579670445590"}},"outputId":"6c0c862f-4da7-4be9-a5b0-7c8835b16821"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8usBzK8VmQsM","executionInfo":{"status":"ok","timestamp":1749118755187,"user_tz":-330,"elapsed":44,"user":{"displayName":"NTR","userId":"00862839579670445590"}},"outputId":"a833b943-f756-4ab7-85dd-14a3fee6be42"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["!mkdir Yolov10-Trainig-CustomModel"],"metadata":{"id":"49g_hSEPmRWm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Yolov10-Trainig-CustomModel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gcOwekkFmWpX","executionInfo":{"status":"ok","timestamp":1749118757871,"user_tz":-330,"elapsed":420,"user":{"displayName":"NTR","userId":"00862839579670445590"}},"outputId":"87cbe20a-f331-4233-b83f-3472ca405c9e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Yolov10-Trainig-CustomModel\n"]}]},{"cell_type":"code","source":["!unzip -q /content/drive/MyDrive/Yolov10-Trainig-CustomModel/unzip.zip -d /content/drive/MyDrive/Yolov10-Trainig-CustomModel/data"],"metadata":{"id":"cm8aho_6Lb2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install ultralytics\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvZS7V5WypW1","executionInfo":{"status":"ok","timestamp":1749119044026,"user_tz":-330,"elapsed":85653,"user":{"displayName":"NTR","userId":"00862839579670445590"}},"outputId":"40376d7f-b821-4d48-fdda-72f4b15fcf17"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.150-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.150-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.150 ultralytics-thop-2.0.14\n"]}]},{"cell_type":"markdown","source":["### **Training **\n","\n","---\n","\n","\n"],"metadata":{"id":"6lo3oxU_lL-e"}},{"cell_type":"code","source":["from ultralytics import YOLO"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nb8Tcmclx98","executionInfo":{"status":"ok","timestamp":1749119054527,"user_tz":-330,"elapsed":4356,"user":{"displayName":"NTR","userId":"00862839579670445590"}},"outputId":"473362f8-291c-4297-c621-67784196ca22"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load your pretrained model\n","model = YOLO(\"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/yolov10m.pt\")  # Adjust the path to your model\n","\n","# Train model\n","model.train(\n","    data=\"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign.yaml\",  # Path to your data file\n","    imgsz=640,\n","    device='cuda',  # Use GPU if available, otherwise use CPU\n","    batch=1,\n","    epochs=30,\n","    patience=50,\n","    project=\"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results\",  # Set output folder in Google Drive\n","    name=\"yolov10_road_sign\",\n","    amp=False\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"B-4ibPzfysQV","executionInfo":{"status":"error","timestamp":1749056277020,"user_tz":-330,"elapsed":742175,"user":{"displayName":"Vishnu","userId":"10651136288565777315"}},"outputId":"130f24ee-abf9-48df-c4cb-36290c39b9fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.149 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/Yolov10-Trainig-CustomModel/yolov10m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov10_road_sign3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 20.8MB/s]"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=4\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n","  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":[" 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n"," 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n"," 23        [16, 19, 22]  1   2285608  ultralytics.nn.modules.head.v10Detect        [4, [192, 384, 576]]          \n","YOLOv10m summary: 288 layers, 16,488,760 parameters, 16,488,744 gradients, 64.0 GFLOPs\n","\n","Transferred 787/799 items from pretrained weights\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 37.4±8.7 MB/s, size: 227.9 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign_splidataset/labels/train... 659 images, 0 backgrounds, 0 corrupt: 100%|██████████| 659/659 [00:06<00:00, 102.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign_splidataset/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.6±0.1 ms, read: 23.8±7.0 MB/s, size: 231.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign_splidataset/labels/val... 82 images, 0 backgrounds, 0 corrupt: 100%|██████████| 82/82 [00:00<00:00, 131.72it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign_splidataset/labels/val.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign3/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign3\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/30       1.8G      1.679      6.484       2.09          3        640: 100%|██████████| 659/659 [01:56<00:00,  5.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:04<00:00,  9.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.528      0.577      0.587      0.459\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/30      1.88G      1.932       2.92      2.273          2        640: 100%|██████████| 659/659 [01:56<00:00,  5.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.546      0.561      0.524      0.378\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/30      1.95G      2.083      2.501      2.342          5        640: 100%|██████████| 659/659 [01:57<00:00,  5.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.553      0.723      0.615      0.436\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/30      1.95G      1.956      2.345      2.325          3        640: 100%|██████████| 659/659 [01:57<00:00,  5.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.843      0.546      0.694      0.499\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/30      1.96G      1.902      2.029      2.283          1        640: 100%|██████████| 659/659 [02:00<00:00,  5.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.936      0.687      0.772       0.54\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/30      2.03G      1.831      2.007      2.241          1        640:  92%|█████████▏| 609/659 [01:52<00:09,  5.42it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-ca505eb4a000>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model.train(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Path to your data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Continue Unfinished training"],"metadata":{"id":"nhnOpw6y4oMA"}},{"cell_type":"code","source":["checkpoint_path = \"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign3/weights/last.pt\"  # Adjust path\n","\n","# Initialize the model from checkpoint\n","model = YOLO(checkpoint_path)  # This loads your saved model (left.pt)\n","\n","# Continue training from the checkpoint\n","model.train(\n","    data=\"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign.yaml\",  # Path to your data\n","    imgsz=640,\n","    device='cuda',  # Use GPU if available, otherwise use CPU\n","    batch=1,\n","    epochs=60,  # Total epochs, even though training continues, you can specify a higher epoch count\n","    patience=50,\n","    project=\"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results\",  # Save results to Google Drive\n","    name=\"yolov10_road_sign\",  # The name of the project\n","    #resume=True,  # This flag ensures that the training continues from where it left off\n","    amp=False\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3pXmYVD4WSS","outputId":"fd0e54d9-66d7-48c0-b7f4-7f224c989d94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.150 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign3/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov10_road_sign5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n","  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n"," 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n"," 23        [16, 19, 22]  1   2285608  ultralytics.nn.modules.head.v10Detect        [4, [192, 384, 576]]          \n","YOLOv10m summary: 288 layers, 16,488,760 parameters, 16,488,744 gradients, 64.0 GFLOPs\n","\n","Transferred 799/799 items from pretrained weights\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 99.1±33.7 MB/s, size: 227.9 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign_splidataset/labels/train.cache... 659 images, 0 backgrounds, 0 corrupt: 100%|██████████| 659/659 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 37.8±79.1 ms, read: 35.4±37.0 MB/s, size: 231.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign_splidataset/labels/val.cache... 82 images, 0 backgrounds, 0 corrupt: 100%|██████████| 82/82 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign5/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign5\u001b[0m\n","Starting training for 60 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/60      1.63G      2.638      2.491       8.31          3        640: 100%|██████████| 659/659 [02:00<00:00,  5.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.77it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.564      0.495      0.457      0.262\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/60      1.63G       2.52       2.53      6.069          2        640: 100%|██████████| 659/659 [01:55<00:00,  5.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.531      0.337      0.365      0.254\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/60      1.95G      2.597      2.698      9.964          5        640: 100%|██████████| 659/659 [01:57<00:00,  5.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.425      0.355      0.262      0.132\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/60      2.03G      2.746      3.068      17.69          3        640: 100%|██████████| 659/659 [01:56<00:00,  5.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.658     0.0858     0.0884     0.0605\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/60      2.11G      2.486      2.637      9.495          1        640: 100%|██████████| 659/659 [01:55<00:00,  5.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.373      0.348      0.297       0.19\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/60      2.19G      2.439       2.51      14.18          2        640: 100%|██████████| 659/659 [01:57<00:00,  5.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.378      0.491       0.35      0.217\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/60      2.19G      2.295      2.252       8.36          4        640: 100%|██████████| 659/659 [01:56<00:00,  5.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 14.55it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.695      0.529      0.605      0.366\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/60      2.19G      2.279      2.261       5.27          1        640: 100%|██████████| 659/659 [01:59<00:00,  5.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.71it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.597      0.581      0.617      0.349\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/60      2.19G      2.268      2.074      7.871          2        640: 100%|██████████| 659/659 [01:56<00:00,  5.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.83it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.505      0.526      0.454      0.316\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/60      2.19G      2.159      2.059      13.97          6        640: 100%|██████████| 659/659 [01:57<00:00,  5.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.99it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.661      0.572      0.559      0.368\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/60      2.27G       2.08      1.963      5.247          2        640: 100%|██████████| 659/659 [01:55<00:00,  5.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 13.96it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.784      0.581       0.63      0.402\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/60      2.27G      2.099      1.894      4.413          2        640: 100%|██████████| 659/659 [01:59<00:00,  5.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.04it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.811      0.578      0.575      0.344\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/60      2.27G      2.092      1.847      27.98          5        640: 100%|██████████| 659/659 [01:55<00:00,  5.69it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.433      0.423      0.402      0.236\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/60      2.27G       2.09      1.971      7.483          4        640: 100%|██████████| 659/659 [01:56<00:00,  5.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.01it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.746       0.68      0.715      0.406\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/60      2.27G      2.087      1.928      6.684          4        640: 100%|██████████| 659/659 [01:59<00:00,  5.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.18it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.781      0.645      0.682      0.427\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/60      2.27G      1.923      1.724      4.267          1        640: 100%|██████████| 659/659 [01:57<00:00,  5.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.89it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.824      0.565       0.66      0.361\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/60      2.27G      2.022      1.795      6.489          1        640: 100%|██████████| 659/659 [01:57<00:00,  5.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.33it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.857      0.628      0.701      0.425\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/60      2.27G      1.936        1.8      5.496          1        640: 100%|██████████| 659/659 [01:56<00:00,  5.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.812      0.563      0.615      0.383\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/60      2.27G      1.969      1.743      4.036          4        640: 100%|██████████| 659/659 [01:57<00:00,  5.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.606      0.542      0.608      0.404\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/60      2.27G      1.874      1.724      7.091          1        640: 100%|██████████| 659/659 [01:56<00:00,  5.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:03<00:00, 13.01it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107        0.6       0.52      0.616      0.399\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      21/60      2.27G      1.823       1.65      4.433          2        640: 100%|██████████| 659/659 [01:56<00:00,  5.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:03<00:00, 12.69it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.574      0.668      0.652      0.434\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      22/60      2.27G      1.828      1.602      10.36          1        640: 100%|██████████| 659/659 [01:58<00:00,  5.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.10it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.699      0.586      0.649      0.456\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      23/60      2.27G      1.889      1.697      8.914          1        640: 100%|██████████| 659/659 [01:57<00:00,  5.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.577      0.692       0.61      0.416\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      24/60      2.27G       1.86       1.57      3.276          4        640: 100%|██████████| 659/659 [01:57<00:00,  5.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 15.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.583        0.6      0.531      0.353\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      25/60      2.27G      1.858      1.589      8.998          1        640: 100%|██████████| 659/659 [01:56<00:00,  5.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:02<00:00, 16.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.708       0.62      0.586      0.354\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      26/60      2.27G       1.87      1.604       4.28          5        640: 100%|██████████| 659/659 [01:56<00:00,  5.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:03<00:00, 13.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.572      0.569      0.515      0.347\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      27/60      2.27G      1.782      1.533      9.813          3        640: 100%|██████████| 659/659 [01:55<00:00,  5.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:03<00:00, 11.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.525      0.688      0.538      0.314\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      28/60      2.27G      1.796       1.59      13.85          1        640: 100%|██████████| 659/659 [01:56<00:00,  5.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 41/41 [00:03<00:00, 11.60it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.648      0.622      0.645      0.382\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      29/60      2.27G      1.829      1.574      4.086          3        640:  35%|███▍      | 229/659 [00:41<01:09,  6.17it/s]"]}]},{"cell_type":"markdown","source":["# Validating best.pt\n","\n","---\n","\n"],"metadata":{"id":"9WLqesElnfLK"}},{"cell_type":"code","source":["# Path to your saved model\n","checkpoint_path = \"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign5/weights/best.pt\"  # Adjust path to your best.pt\n","\n","# Initialize the model from the checkpoint\n","model = YOLO(checkpoint_path)  # This loads your saved model (best.pt)\n","\n","# Path to your dataset YAML file\n","data_path = \"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign.yaml\"\n","\n","# Evaluate the model and get mAP (mean Average Precision)\n","metrics = model.val(data=data_path)  # This will evaluate your model on the validation dataset\n","\n","# Print mAP\n","print(f\"mAP: {metrics.maps[0]:.4f}\")  # mAP at IoU=0.5, change it based on your needs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDgW6pMHnepT","executionInfo":{"status":"ok","timestamp":1749119338554,"user_tz":-330,"elapsed":220183,"user":{"displayName":"NTR","userId":"00862839579670445590"}},"outputId":"50c45767-07ed-493a-dd61-2ad28cf26db2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.150 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (AMD EPYC 7B12)\n","YOLOv10m summary (fused): 136 layers, 15,315,484 parameters, 0 gradients, 58.9 GFLOPs\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 4.11MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.6±0.4 ms, read: 0.3±0.1 MB/s, size: 219.9 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Yolov10-Trainig-CustomModel/data/road_sign_splidataset/labels/val.cache... 82 images, 0 backgrounds, 0 corrupt: 100%|██████████| 82/82 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [03:15<00:00, 32.58s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         82        107      0.759      0.608       0.69      0.459\n","                  Stop          6          6      0.646      0.333      0.515      0.318\n","             Crosswalk         70         84      0.796      0.786       0.82      0.582\n","          Trafficlight         16         17      0.836      0.706      0.735      0.476\n","Speed: 3.8ms preprocess, 1072.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n","mAP: 0.4585\n"]}]},{"cell_type":"code","source":["!unzip -q /content/drive/MyDrive/Yolov10-Trainig-CustomModel/inference-20250605T055637Z-1-001.zip -d /content/drive/MyDrive/Yolov10-Trainig-CustomModel/"],"metadata":{"id":"TQFxJfPbrv92"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DETECTION USING INFERENCE FOLDER"],"metadata":{"id":"jhdNEEF0p_1T"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","import cv2\n","import os\n","\n","# Load the trained model\n","checkpoint_path = \"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/results/yolov10_road_sign3/weights/best.pt\"  # Adjust path\n","model = YOLO(checkpoint_path)\n","\n","# Function to handle detection for images and videos\n","def detect(input_path):\n","    # Check if input is an image or video based on file extension\n","    if input_path.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n","        # Image detection\n","        img = cv2.imread(input_path)  # Read image\n","        results = model(img)  # Perform detection\n","        results[0].save()  # Save the annotated image to the 'runs' folder\n","        print(f\"Detection for image {input_path} completed.\")\n","\n","    elif input_path.endswith('.mp4'):\n","        # Video detection\n","        cap = cv2.VideoCapture(input_path)\n","        fps = cap.get(cv2.CAP_PROP_FPS)\n","        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","        # Define video writer to save output\n","        video_output_path = os.path.join(\"runs\", \"detect\", \"output_video.mp4\")\n","        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","        out = cv2.VideoWriter(video_output_path, fourcc, fps, (frame_width, frame_height))\n","\n","        while cap.isOpened():\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            results = model(frame)  # Perform detection on frame\n","            annotated_frame = results[0].plot()  # Add bounding boxes to frame\n","            out.write(annotated_frame)  # Write frame to output video\n","\n","        cap.release()\n","        out.release()\n","        print(f\"Detection for video {input_path} completed. Output saved to {video_output_path}\")\n","\n","    else:\n","        print(f\"Unsupported file format for {input_path}\")\n","\n","# Change this to the path of your image or video file\n","input_path = \"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/inference/road-sign.mp4\"  # Example for image\n","# input_path = \"/content/drive/MyDrive/Yolov10-Trainig-CustomModel/inference/input_video.mp4\"  # Example for video\n","\n","# Detect based on the input path\n","detect(input_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Cdno_vtp_KU","executionInfo":{"status":"ok","timestamp":1749104871666,"user_tz":-330,"elapsed":290978,"user":{"displayName":"Vishnu","userId":"10651136288565777315"}},"outputId":"4a195c3c-a951-45fc-b969-fea7765163ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 (no detections), 852.0ms\n","Speed: 8.0ms preprocess, 852.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 850.8ms\n","Speed: 4.6ms preprocess, 850.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 861.9ms\n","Speed: 4.6ms preprocess, 861.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 816.3ms\n","Speed: 3.5ms preprocess, 816.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 833.8ms\n","Speed: 3.9ms preprocess, 833.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 859.0ms\n","Speed: 3.7ms preprocess, 859.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 862.6ms\n","Speed: 3.8ms preprocess, 862.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1272.8ms\n","Speed: 4.2ms preprocess, 1272.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1327.5ms\n","Speed: 5.6ms preprocess, 1327.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1353.3ms\n","Speed: 7.3ms preprocess, 1353.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1148.0ms\n","Speed: 4.2ms preprocess, 1148.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 897.3ms\n","Speed: 3.7ms preprocess, 897.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 846.7ms\n","Speed: 4.0ms preprocess, 846.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 821.6ms\n","Speed: 3.6ms preprocess, 821.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 849.4ms\n","Speed: 3.6ms preprocess, 849.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 809.5ms\n","Speed: 4.2ms preprocess, 809.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 794.0ms\n","Speed: 3.2ms preprocess, 794.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 895.4ms\n","Speed: 3.4ms preprocess, 895.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 876.6ms\n","Speed: 4.4ms preprocess, 876.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 858.3ms\n","Speed: 4.7ms preprocess, 858.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 870.1ms\n","Speed: 4.0ms preprocess, 870.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 862.0ms\n","Speed: 3.6ms preprocess, 862.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1262.1ms\n","Speed: 4.0ms preprocess, 1262.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1297.2ms\n","Speed: 4.7ms preprocess, 1297.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1332.1ms\n","Speed: 4.1ms preprocess, 1332.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1083.5ms\n","Speed: 4.2ms preprocess, 1083.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 871.3ms\n","Speed: 3.8ms preprocess, 871.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 871.0ms\n","Speed: 3.9ms preprocess, 871.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 864.2ms\n","Speed: 4.0ms preprocess, 864.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 805.2ms\n","Speed: 3.9ms preprocess, 805.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 836.4ms\n","Speed: 3.7ms preprocess, 836.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 873.4ms\n","Speed: 4.5ms preprocess, 873.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 874.2ms\n","Speed: 4.1ms preprocess, 874.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 807.8ms\n","Speed: 3.4ms preprocess, 807.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 808.9ms\n","Speed: 3.4ms preprocess, 808.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 846.0ms\n","Speed: 3.6ms preprocess, 846.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 833.3ms\n","Speed: 3.9ms preprocess, 833.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1303.1ms\n","Speed: 3.7ms preprocess, 1303.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1282.7ms\n","Speed: 4.0ms preprocess, 1282.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1268.8ms\n","Speed: 3.5ms preprocess, 1268.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1054.5ms\n","Speed: 5.8ms preprocess, 1054.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 832.8ms\n","Speed: 4.4ms preprocess, 832.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 843.7ms\n","Speed: 3.6ms preprocess, 843.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 882.2ms\n","Speed: 5.9ms preprocess, 882.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 803.9ms\n","Speed: 4.1ms preprocess, 803.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 868.3ms\n","Speed: 3.5ms preprocess, 868.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 815.1ms\n","Speed: 4.0ms preprocess, 815.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 797.5ms\n","Speed: 3.8ms preprocess, 797.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 823.5ms\n","Speed: 3.7ms preprocess, 823.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 901.5ms\n","Speed: 4.1ms preprocess, 901.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 886.5ms\n","Speed: 3.8ms preprocess, 886.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 823.8ms\n","Speed: 3.9ms preprocess, 823.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1248.3ms\n","Speed: 3.1ms preprocess, 1248.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1319.7ms\n","Speed: 7.3ms preprocess, 1319.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1327.0ms\n","Speed: 6.3ms preprocess, 1327.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1003.5ms\n","Speed: 3.8ms preprocess, 1003.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 845.8ms\n","Speed: 3.4ms preprocess, 845.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 845.1ms\n","Speed: 3.8ms preprocess, 845.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 824.2ms\n","Speed: 3.3ms preprocess, 824.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 859.7ms\n","Speed: 3.6ms preprocess, 859.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 791.6ms\n","Speed: 5.2ms preprocess, 791.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 856.5ms\n","Speed: 3.6ms preprocess, 856.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 885.0ms\n","Speed: 3.6ms preprocess, 885.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 853.8ms\n","Speed: 3.7ms preprocess, 853.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 832.0ms\n","Speed: 3.8ms preprocess, 832.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 792.0ms\n","Speed: 3.5ms preprocess, 792.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 806.6ms\n","Speed: 3.5ms preprocess, 806.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1205.7ms\n","Speed: 4.6ms preprocess, 1205.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1258.6ms\n","Speed: 3.4ms preprocess, 1258.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 1324.4ms\n","Speed: 7.6ms preprocess, 1324.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 1 Crosswalk, 1173.0ms\n","Speed: 4.3ms preprocess, 1173.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 1 Crosswalk, 864.5ms\n","Speed: 4.1ms preprocess, 864.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 1063.4ms\n","Speed: 3.7ms preprocess, 1063.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 1340.7ms\n","Speed: 5.2ms preprocess, 1340.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 1321.7ms\n","Speed: 4.0ms preprocess, 1321.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 2 Crosswalks, 1313.3ms\n","Speed: 7.3ms preprocess, 1313.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 911.9ms\n","Speed: 4.8ms preprocess, 911.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 866.2ms\n","Speed: 4.0ms preprocess, 866.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 902.7ms\n","Speed: 4.2ms preprocess, 902.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 2 Crosswalks, 946.1ms\n","Speed: 3.9ms preprocess, 946.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 1355.4ms\n","Speed: 3.8ms preprocess, 1355.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 1258.7ms\n","Speed: 4.1ms preprocess, 1258.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 1264.5ms\n","Speed: 9.4ms preprocess, 1264.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 885.6ms\n","Speed: 3.5ms preprocess, 885.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 806.5ms\n","Speed: 3.9ms preprocess, 806.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 870.1ms\n","Speed: 3.9ms preprocess, 870.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 882.7ms\n","Speed: 5.2ms preprocess, 882.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 832.6ms\n","Speed: 3.6ms preprocess, 832.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 889.4ms\n","Speed: 3.2ms preprocess, 889.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 836.2ms\n","Speed: 4.1ms preprocess, 836.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 851.8ms\n","Speed: 4.6ms preprocess, 851.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 857.0ms\n","Speed: 5.8ms preprocess, 857.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 846.8ms\n","Speed: 3.8ms preprocess, 846.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 869.5ms\n","Speed: 4.1ms preprocess, 869.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 933.2ms\n","Speed: 3.6ms preprocess, 933.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1293.8ms\n","Speed: 3.4ms preprocess, 1293.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1293.7ms\n","Speed: 5.7ms preprocess, 1293.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1304.6ms\n","Speed: 3.7ms preprocess, 1304.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 975.8ms\n","Speed: 4.9ms preprocess, 975.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 885.7ms\n","Speed: 4.0ms preprocess, 885.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 869.1ms\n","Speed: 4.7ms preprocess, 869.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 838.2ms\n","Speed: 3.8ms preprocess, 838.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 859.1ms\n","Speed: 3.4ms preprocess, 859.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 846.4ms\n","Speed: 3.8ms preprocess, 846.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 790.4ms\n","Speed: 3.3ms preprocess, 790.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 863.8ms\n","Speed: 3.3ms preprocess, 863.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 857.6ms\n","Speed: 4.3ms preprocess, 857.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 837.1ms\n","Speed: 3.9ms preprocess, 837.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 819.2ms\n","Speed: 3.6ms preprocess, 819.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 851.8ms\n","Speed: 3.8ms preprocess, 851.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1231.9ms\n","Speed: 8.0ms preprocess, 1231.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1287.9ms\n","Speed: 4.4ms preprocess, 1287.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1358.5ms\n","Speed: 3.9ms preprocess, 1358.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 969.0ms\n","Speed: 3.8ms preprocess, 969.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 853.6ms\n","Speed: 4.6ms preprocess, 853.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 811.7ms\n","Speed: 4.1ms preprocess, 811.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 809.0ms\n","Speed: 3.3ms preprocess, 809.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 853.9ms\n","Speed: 6.0ms preprocess, 853.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 887.9ms\n","Speed: 3.8ms preprocess, 887.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 896.5ms\n","Speed: 4.3ms preprocess, 896.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 858.7ms\n","Speed: 3.8ms preprocess, 858.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 828.4ms\n","Speed: 3.7ms preprocess, 828.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 868.7ms\n","Speed: 3.6ms preprocess, 868.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 863.8ms\n","Speed: 4.3ms preprocess, 863.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1008.2ms\n","Speed: 3.9ms preprocess, 1008.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1336.3ms\n","Speed: 4.0ms preprocess, 1336.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1242.4ms\n","Speed: 3.4ms preprocess, 1242.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1281.5ms\n","Speed: 3.6ms preprocess, 1281.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 931.9ms\n","Speed: 3.9ms preprocess, 931.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 828.2ms\n","Speed: 4.9ms preprocess, 828.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 795.0ms\n","Speed: 3.3ms preprocess, 795.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 806.9ms\n","Speed: 3.3ms preprocess, 806.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 821.4ms\n","Speed: 3.7ms preprocess, 821.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 814.8ms\n","Speed: 3.6ms preprocess, 814.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 807.8ms\n","Speed: 4.8ms preprocess, 807.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 779.2ms\n","Speed: 3.2ms preprocess, 779.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 810.1ms\n","Speed: 5.0ms preprocess, 810.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 794.7ms\n","Speed: 3.7ms preprocess, 794.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 805.3ms\n","Speed: 3.4ms preprocess, 805.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 837.7ms\n","Speed: 6.8ms preprocess, 837.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1269.3ms\n","Speed: 4.2ms preprocess, 1269.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1244.4ms\n","Speed: 3.9ms preprocess, 1244.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1334.1ms\n","Speed: 3.6ms preprocess, 1334.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1121.0ms\n","Speed: 4.1ms preprocess, 1121.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 834.0ms\n","Speed: 3.5ms preprocess, 834.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 852.6ms\n","Speed: 3.8ms preprocess, 852.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 856.3ms\n","Speed: 4.0ms preprocess, 856.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 854.0ms\n","Speed: 3.8ms preprocess, 854.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 808.6ms\n","Speed: 4.0ms preprocess, 808.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 844.4ms\n","Speed: 3.3ms preprocess, 844.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 901.7ms\n","Speed: 4.3ms preprocess, 901.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 845.2ms\n","Speed: 3.8ms preprocess, 845.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 856.5ms\n","Speed: 3.3ms preprocess, 856.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 927.6ms\n","Speed: 4.1ms preprocess, 927.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 848.8ms\n","Speed: 3.5ms preprocess, 848.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1242.5ms\n","Speed: 3.3ms preprocess, 1242.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1224.7ms\n","Speed: 3.3ms preprocess, 1224.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1219.7ms\n","Speed: 3.3ms preprocess, 1219.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 1021.9ms\n","Speed: 6.0ms preprocess, 1021.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 840.3ms\n","Speed: 4.0ms preprocess, 840.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 868.0ms\n","Speed: 3.9ms preprocess, 868.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 851.4ms\n","Speed: 3.8ms preprocess, 851.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 781.3ms\n","Speed: 6.1ms preprocess, 781.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 805.7ms\n","Speed: 3.7ms preprocess, 805.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 826.8ms\n","Speed: 3.6ms preprocess, 826.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 809.4ms\n","Speed: 3.3ms preprocess, 809.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 786.4ms\n","Speed: 3.3ms preprocess, 786.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 795.0ms\n","Speed: 5.8ms preprocess, 795.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 809.6ms\n","Speed: 3.3ms preprocess, 809.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 807.1ms\n","Speed: 4.1ms preprocess, 807.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 1088.3ms\n","Speed: 3.9ms preprocess, 1088.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1307.7ms\n","Speed: 10.2ms preprocess, 1307.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1281.2ms\n","Speed: 5.9ms preprocess, 1281.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1260.8ms\n","Speed: 4.3ms preprocess, 1260.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 869.6ms\n","Speed: 4.0ms preprocess, 869.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 861.6ms\n","Speed: 4.4ms preprocess, 861.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 850.2ms\n","Speed: 4.0ms preprocess, 850.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 869.5ms\n","Speed: 4.2ms preprocess, 869.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 865.8ms\n","Speed: 4.0ms preprocess, 865.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 818.8ms\n","Speed: 4.3ms preprocess, 818.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 790.8ms\n","Speed: 3.7ms preprocess, 790.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 807.5ms\n","Speed: 3.9ms preprocess, 807.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 820.1ms\n","Speed: 3.4ms preprocess, 820.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 803.4ms\n","Speed: 3.5ms preprocess, 803.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 816.8ms\n","Speed: 3.5ms preprocess, 816.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1084.4ms\n","Speed: 3.7ms preprocess, 1084.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1308.8ms\n","Speed: 4.1ms preprocess, 1308.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1286.9ms\n","Speed: 3.8ms preprocess, 1286.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1213.8ms\n","Speed: 3.8ms preprocess, 1213.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 826.1ms\n","Speed: 4.1ms preprocess, 826.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 852.0ms\n","Speed: 3.7ms preprocess, 852.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 854.9ms\n","Speed: 4.2ms preprocess, 854.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 800.4ms\n","Speed: 3.9ms preprocess, 800.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 795.7ms\n","Speed: 3.1ms preprocess, 795.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 854.4ms\n","Speed: 3.6ms preprocess, 854.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 831.9ms\n","Speed: 3.9ms preprocess, 831.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 812.5ms\n","Speed: 7.0ms preprocess, 812.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 815.7ms\n","Speed: 3.2ms preprocess, 815.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 866.9ms\n","Speed: 4.3ms preprocess, 866.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 816.9ms\n","Speed: 3.7ms preprocess, 816.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1052.3ms\n","Speed: 3.3ms preprocess, 1052.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1268.6ms\n","Speed: 6.4ms preprocess, 1268.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1336.8ms\n","Speed: 7.9ms preprocess, 1336.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1288.4ms\n","Speed: 4.1ms preprocess, 1288.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 867.5ms\n","Speed: 4.4ms preprocess, 867.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 823.6ms\n","Speed: 4.0ms preprocess, 823.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 821.0ms\n","Speed: 3.5ms preprocess, 821.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 820.6ms\n","Speed: 3.3ms preprocess, 820.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 862.7ms\n","Speed: 5.5ms preprocess, 862.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 865.9ms\n","Speed: 4.3ms preprocess, 865.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 865.4ms\n","Speed: 4.6ms preprocess, 865.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 863.7ms\n","Speed: 4.3ms preprocess, 863.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 839.8ms\n","Speed: 3.8ms preprocess, 839.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 866.9ms\n","Speed: 3.9ms preprocess, 866.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 868.4ms\n","Speed: 4.4ms preprocess, 868.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1201.0ms\n","Speed: 4.0ms preprocess, 1201.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1347.4ms\n","Speed: 6.1ms preprocess, 1347.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1324.4ms\n","Speed: 3.9ms preprocess, 1324.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1137.7ms\n","Speed: 3.6ms preprocess, 1137.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 843.7ms\n","Speed: 4.0ms preprocess, 843.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 856.4ms\n","Speed: 3.9ms preprocess, 856.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 828.6ms\n","Speed: 6.1ms preprocess, 828.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 800.8ms\n","Speed: 3.2ms preprocess, 800.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 792.3ms\n","Speed: 3.2ms preprocess, 792.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 799.6ms\n","Speed: 3.6ms preprocess, 799.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 862.9ms\n","Speed: 4.0ms preprocess, 862.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 883.6ms\n","Speed: 3.9ms preprocess, 883.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 865.9ms\n","Speed: 4.4ms preprocess, 865.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 829.6ms\n","Speed: 3.7ms preprocess, 829.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 859.3ms\n","Speed: 3.4ms preprocess, 859.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1190.4ms\n","Speed: 3.7ms preprocess, 1190.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 1302.9ms\n","Speed: 5.6ms preprocess, 1302.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1287.8ms\n","Speed: 4.0ms preprocess, 1287.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 1114.6ms\n","Speed: 3.9ms preprocess, 1114.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 812.0ms\n","Speed: 3.4ms preprocess, 812.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 808.5ms\n","Speed: 3.3ms preprocess, 808.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 809.6ms\n","Speed: 3.4ms preprocess, 809.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 856.0ms\n","Speed: 6.7ms preprocess, 856.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 845.6ms\n","Speed: 3.8ms preprocess, 845.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 850.7ms\n","Speed: 5.4ms preprocess, 850.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 837.3ms\n","Speed: 3.2ms preprocess, 837.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 856.0ms\n","Speed: 3.6ms preprocess, 856.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 874.8ms\n","Speed: 3.9ms preprocess, 874.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 874.9ms\n","Speed: 4.0ms preprocess, 874.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 882.3ms\n","Speed: 3.5ms preprocess, 882.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1326.4ms\n","Speed: 4.0ms preprocess, 1326.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1337.0ms\n","Speed: 9.3ms preprocess, 1337.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1347.4ms\n","Speed: 4.5ms preprocess, 1347.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1070.5ms\n","Speed: 4.3ms preprocess, 1070.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 883.4ms\n","Speed: 4.0ms preprocess, 883.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 874.6ms\n","Speed: 5.8ms preprocess, 874.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 818.4ms\n","Speed: 3.8ms preprocess, 818.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 826.6ms\n","Speed: 3.5ms preprocess, 826.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 844.5ms\n","Speed: 4.0ms preprocess, 844.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Crosswalk, 855.6ms\n","Speed: 4.0ms preprocess, 855.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Crosswalks, 807.6ms\n","Speed: 3.3ms preprocess, 807.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 804.5ms\n","Speed: 3.2ms preprocess, 804.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 856.6ms\n","Speed: 3.6ms preprocess, 856.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 830.0ms\n","Speed: 4.4ms preprocess, 830.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 855.8ms\n","Speed: 5.0ms preprocess, 855.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1296.5ms\n","Speed: 4.7ms preprocess, 1296.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 1275.8ms\n","Speed: 3.7ms preprocess, 1275.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 1307.8ms\n","Speed: 4.7ms preprocess, 1307.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 1079.2ms\n","Speed: 3.4ms preprocess, 1079.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 853.7ms\n","Speed: 4.0ms preprocess, 853.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 858.3ms\n","Speed: 4.0ms preprocess, 858.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 Stops, 857.4ms\n","Speed: 4.4ms preprocess, 857.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 827.6ms\n","Speed: 4.6ms preprocess, 827.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 806.1ms\n","Speed: 4.3ms preprocess, 806.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 804.6ms\n","Speed: 3.3ms preprocess, 804.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Stop, 808.6ms\n","Speed: 3.6ms preprocess, 808.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 802.6ms\n","Speed: 4.7ms preprocess, 802.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 823.4ms\n","Speed: 3.4ms preprocess, 823.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 843.1ms\n","Speed: 3.5ms preprocess, 843.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 846.7ms\n","Speed: 8.4ms preprocess, 846.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1205.4ms\n","Speed: 3.7ms preprocess, 1205.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1248.5ms\n","Speed: 4.5ms preprocess, 1248.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1306.5ms\n","Speed: 3.7ms preprocess, 1306.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1219.3ms\n","Speed: 5.6ms preprocess, 1219.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 824.4ms\n","Speed: 4.4ms preprocess, 824.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 815.3ms\n","Speed: 3.9ms preprocess, 815.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 812.6ms\n","Speed: 3.4ms preprocess, 812.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 821.9ms\n","Speed: 5.2ms preprocess, 821.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 932.2ms\n","Speed: 3.6ms preprocess, 932.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 868.4ms\n","Speed: 4.2ms preprocess, 868.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 829.1ms\n","Speed: 6.6ms preprocess, 829.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 822.7ms\n","Speed: 3.5ms preprocess, 822.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 857.2ms\n","Speed: 3.7ms preprocess, 857.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 891.8ms\n","Speed: 4.2ms preprocess, 891.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 862.9ms\n","Speed: 3.8ms preprocess, 862.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1237.4ms\n","Speed: 3.7ms preprocess, 1237.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1235.6ms\n","Speed: 5.2ms preprocess, 1235.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1306.2ms\n","Speed: 3.5ms preprocess, 1306.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 1194.7ms\n","Speed: 9.1ms preprocess, 1194.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 861.5ms\n","Speed: 4.9ms preprocess, 861.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","Detection for video /content/drive/MyDrive/Yolov10-Trainig-CustomModel/inference/road-sign.mp4 completed. Output saved to runs/detect/output_video.mp4\n"]}]}]}